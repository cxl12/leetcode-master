# 操作系统面试内容

* 什么是操作系统
  * 操作系统（Operating System，OS）是软件的一部分，它是硬件基础上的第一层软件，是硬件和其它软件沟通的桥梁（或者说接口、中间人、中介等）；操作系统在给其他软件提供各种便利的同时，还会约束其他软件不能为所欲为。
  * 组成
    * 文件系统
      * 提供计算机存储信息的结构
    * 设备驱动程序
      * 提供连接计算机的每个硬件设备的接口，设备驱动器使程序能够写入设备，而不需要了解执行每个硬件的细节。简单来说，就是让你能吃到鸡蛋，但不用养一只鸡。
    * shell
      * 操作系统需要为用户提供一种运行程序和访问文件系统的方法。如常用的 Windows 图形界面，可以理解为一种用户与操作系统交互的方式；智能手机的 Android 或 iOS 系统，也是一种操作系统的交互方式。
    * 系统服务程序
      * 当计算机启动时，会自启动许多系统服务程序，执行安装文件系统、启动网络服务、运行预定任务等操作。
  * 内存管理
  * 进程管理
  * ...

## 进程与线程

* 进程的内存布局
  * 栈
    * 向下发展
  * 堆
    * 向上发展
  * 初始化的数据段
  * 未初始化的数据段
  * 程序代码段

* 进程与线程的区别?
  * 进程指的是一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程
    * 进程的状态
      * 进程的基本状态主要有就绪态，运行态，阻塞态
      * 当进程已分配到除CPU以外的所有必要资源后，只要再获得CPU，便可立即执行，进程这时的状态称为就绪状态，加入就绪队列中
      * 运行状态：进程已获得CPU，正在运行
      * 阻塞状态：正在执行的进程由于发生某事件或等待某种资源而暂时无法继续执行时，便放弃处理机而处于暂停状态
    * 进程的状态转换
      * 就绪态进程分配到CPU进入运行态，运行态进程的CPU时间片用完，进入就绪态
      * 运行态进程因等待某些资源或者事件的发生，而无法继续执行，放弃CPU进入阻塞态
      * 阻塞态进程所等待的资源到达或等待的事件发生，进入就绪态

  * 线程是进程中的一个执行任务（控制单元），负责当前进程中程序的执行。一个进程可以运行多个线程但至少有一个线程，多个线程可共享数据。
    * 线程的四种状态
      * 新建态，就绪态，运行态，阻塞态
      * 新建状态（New）：新创建了一个线程对象，分配了资源。
      * 运行状态（Running）：就绪状态的线程获取了CPU，执行程序代码。
      * 阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：

  * 区别：就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。

    * 根本区别：进程是资源分配的最小单位，线程是程序执行的最小单位（资源调度的最小单位）
    * 内存分配：进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作时间花销非常大。而线程是共享进程中的数据的，一个进程的多个线程使用相同的地址空间，因此CPU切换一个线程花销远比进程要小很多，同时创建一个线程的开销也比进程要小很多。  
  * 通信：进程之间的通信需要以通信的方式（IPC)进行。线程之间的通信更方便，同一进程下的多个线程共享全局变量、静态变量等数据，不过如何处理好同步与互斥是编写多线程程序的难点。

* 影响关系：
  * 由于进程之间独立的特点，使得进程安全性比较高，也因为进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。
  * 一个线程死掉就等于整个进程死掉所以多进程要比多线程健壮。

* 孤儿进程
  * 孤儿进程可以理解为一个子进程的父进程英年早逝（父进程先于子进程退出），就将这样的一个进程称为孤儿进程，在linux操作系统上。孤儿进程被init进程收养，此时孤儿进程的ppid==1，即init进程的pid == 1。也就是说init进程变成孤儿进程的父进程（干爹）
  * 其目的只有一个，就是为了释放系统资源，进程结束之后，能够释放用户区空间。但不能释放pcb（进程控制块），即内核资源。pcb必须由子进程的父进程进行释放。

* 僵尸进程
  * 父进程成功创建子进程，且子进程先于父进程退出。
  * 子进程需要父进程回收其所占资源，释放pcb。但是父进程不作为，不去释放已经退出子进程的pcb。
  * 这样的子进程变为僵尸进程。
  * 僵尸进程是一个已经死掉了的进程。

* 如何回收僵尸进程的资源
  * 回收僵尸进程的资源，一种比较暴力的做法是将其父进程杀死，那么子进程资源也将被回收。但是这种做法在大多数情况下都是不可取的，如父进程是一个服务器程序，如果为了回收其子进程的资源，而杀死服务器程序，那么将导致整个服务器崩溃，得不偿失。显然这种回收进程的方式是不可取的，但其也有一定的存在意义。那么有没有更好的解决方案呢，且看下边的两种方式。
  * 注：kipp -9 + (父进程的pid)是第一种回收子进程资源的方式

* wait系统调用函数
  * pid_t wait(int* status)，是一个阻塞函数。
  * 返回值：如果为-1,回收失败，已经没有子进程可以回收了。如果 > 0,返回值为子进程对应的pid。
  * 参数：子进程的退出状态，是一个传出参数。判断子进程是如何死的
    * （1）正常退出
    * （2）被信号杀死
  * 调用一次，只能回收一个子进程，如果回收多个子进程，就需要多次调用wait函数。
  * 函数功能：
    * （1）阻塞并等待子进程退出。
    * （2）回收子进程残留资源。
    * （3）获取子进程结束状态（退出原因）。

* 用户级线程和内核级线程的区别（深信服）
  * 内核级线程:切换由内核控制，当线程进行切换的时候，由用户态转化为内核态。切换完毕要从内核态返回用户态
  * 用户级线程： 指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心自己控制内核切换,不需要内核干涉，少了进出内核态的消耗，
  * 区别：
    * 用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。
    * 用户级线程的创建、撤消和调度不需要OS内核的支持，是在语言（如Java）这一级处理的；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。
    * 内核线程依赖与内核，可以像多进程一样并行执行，用户今晨不依赖内核

* linux的进程调度算法
  * 先来先去服务
  * 短作业(进程)优先调度算法
  * 时间轮片法：让每个进程在就绪队列中的等待时间与享受服务的时间成正比例。
  * 多级反馈队列算法
    * 设置多个就绪队列，分别赋予不同的优先级，如逐级降低，队列1的优先级最高。每个队列执行时间片的长度也不同，规定优先级越低则时间片越长，如逐级加倍。

* 什么时候用多进程什么时候用多线程？
* 进程与线程的选择取决以下几点：
  * 1、需要频繁创建销毁的优先使用线程；因为对进程来说创建和销毁一个进程代价是很大的。
  * 2、线程的切换速度快，所以在需要大量计算，切换频繁时用线程，还有耗时的操作使用线程可提高应用程序的响应
  * 3、因为对CPU系统的效率使用上线程更占优，所以可能要发展到多机分布的用进程，多核分布用线程；
  * 4、并行操作时使用线程，如C/S架构的服务器端并发线程响应用户的请求
  * 5、需要更稳定安全时，适合选择进程；需要速度时，选择线程更好

  * 系统接受实现多用户多请求的高并发时，通过多线程来实现
  * 线程后台处理大任务
    * 一个程序是线性执行的。如果程序执行到要花大量时间处理的任务时，那主程序就得等待其执行完才能继续执行下面的。那用户就不得不等待它执行完。
    * 这时候可以开线程把花大量时间处理的任务放在线程处理，这样线程在后台处理时或者等待资源，主程序也可以继续执行下去，用户就不需要等待。线程执行完后执行回调函数
  * 大任务
    * 大任务处理起来比较耗时，这时候可以起到多个线程并行加快处理（例如：分片上传）

  * 为什么进程开销比线程大？
    * 因为进程拥有独立的堆栈空间和数据段，所以每当启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段
    * 线程不一样，线程拥有独立的堆栈空间（堆栈是指运行中的栈空间），但是共享数据段，它们彼此之间使用相同的进程地址空间，共享大部分数据，比进程更节俭，开销比较小，切换速度也比进程快，效率高，

* 同一个进程的不同线程之间共享的数据有哪些？
  * 线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈），其余的堆等进程资源是所有线程之间共享的。

  * 堆：是大家共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏

  * 栈：是个线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立，因此，栈是　thread safe的。操作系统在切换线程的时候会自动的切换栈，就是切换 ＳＳ／ＥＳＰ寄存器。栈空间不需要在高级语言里面显式的分配和释放

* 线程安全
  * 如果多个线程在同时运行，那么这些线程就可能同时运行这段代码。程序每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也是和预期一样的，是线程安全的。
  * 线程安全问题都是由全局变量及静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。
  * 可以通过加锁解决线程安全问题
  * c++可以用头文件<thread>，<atomic> <mutex>等实现多线程的并发同步

* 了解过哪些锁

  * 包括互斥锁（mutex)、条件锁、读写锁，自旋锁

  * 互斥锁提供了以排他方式防止数据结构被并发修改的方法，线程之间的互斥量通信方式就是应用了互斥锁,互斥锁用于控制多个线程对他们之间共享资源互斥访问的一个信号量。也就是说是为了避免多个线程在某一时刻同时操作一个共享资源。处理器不会因为线程阻塞而空闲着，它去处理其他事务去，不用一直检查是否能够加锁，让出CPU给别的线程先执行。
    * 例如线程池中的有多个空闲线程和一个任务队列。任何是一个线程都要使用互斥锁互斥访问任务队列，以避免多个线程同时访问任务队列以发生错乱。

  * 条件锁：条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用
    * 某一个线程因为某个条件为满足时可以使用条件变量使改程序处于阻塞状态。一旦条件满足以“信号量”的方式唤醒一个因为该条件而被阻塞的线程。
      * 就像生产者和消费者模式中，最为常见的就是在线程池中，起初没有任务时任务队列为空，此时线程池中的线程因为“任务队列为空”这个条件处于阻塞状态。一旦有任务进来，就会以信号量的方式唤醒一个线程来处理这个任务。

  * 读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
    * 如允许在数据库上同时执行多个“读”操作，但是某一时刻只能在数据库上有一个“写”操作来更新数据

  * 自旋锁
    * 自旋锁是为了抢占式调度。两个线程在使用共享资源前，需要申请自旋锁，一个线程在使用自旋锁，而另一个线程也要访问共享资源，它也想获得自旋锁，它会一直不断地循环检查锁是否可用（自旋锁请求），直到获取到这个自旋锁为止，这个过程中CPU一直被占用。

* 死锁：
  * 一组进程中每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程是死锁的。
  * 有两个进程A和B,A持有资源a等待b资源，B持有资源b等待a资源，两个进程都在等待另一个资源的同时不释放资源，就形成死锁。
  * 形成死锁的四个必要条件
    * 互斥条件：一个资源每次只能被一个进程使用。
    * 占有且等待：—个进程应占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有
    * 非抢占：资源不能被抢占，即资源只能被进程在完成任务后自愿释放。
    * 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

* 解决死锁
  * 预防死锁： 破坏四个必要条件中的一个或多个来预防死锁
  * 避免死锁：在资源动态分配的过程中，用某种方式防止系统进入不安全的状态（银行家算法）
  * 检测死锁：可以允许系统进入死锁状态，然后检测它，并加以恢复。
  * 解除死锁：发生死锁后，撤销进程，回收资源，分配给正在阻塞状态的进程。
  * 可以忽视这个问题，认为死锁不可能在系统内发生，大多数操作系统所采用，包括 Linux 和 Windows。因此，应用程序开发人员需要自己编写程序，以便处理死锁。

* 死锁的解除办法：
  * 1、抢占资源。从一个或多个进程中抢占足够数量的资源，分配给死锁进程，以解除死锁状态。
  * 2、终止（撤销）进程：将一个或多个思索进程终止（撤销），直至打破循环环路，使系统从死锁状态解脱

* 线程变量
  * 一个进程中定义的全局或静态变量都是所有线程可见的，即每个线程共同操作一块存储区域。
  * 而有时我们可能有这样的需求：对于一个全局变量，每个线程对其的修改只在本线程内有效，各线程之间互不干扰。即每个线程虽然共享这个全局变量的名字，但这个变量的值就像只有在本线程内才会被修改和读取一样。
    * 线程局部存储和线程特有数据都可以实现上述需求。
      * 线程局部存储
        * 提供了持久的每线程存储，每个线程都拥有一份对变量的拷贝，线程局部存储中的变量将一直存在，直到线程终止，届时会自动释放这一存储，每个线程都有自己的一份errno的拷贝，防止了一个线程获取errno时被其他线程干扰。要定义一个线程局部变量很简单，只需简单的在全局或静态变量的声明中包含__thread说明符即可
          * static __thread int buf[MAX_ERROR_LEN];
        * 这样定义的变量，在一个线程中只能看到本线程对其的修改
          * 如果变量声明中使用了关键字static或extern，那么关键字__thread必须紧随其后
          * 与一般的全局或静态变量声明一样，线程局部变量在声明时可以设置一个初始值。初始化的值必须是一个常量表达式。
          * 可以使用C语言取址操作符（&）来获取线程局部变量的地址。
        * 线程特有数据
          * POSIX thread使用getthreadspecific和setthreadspecific 组件来实现这一特性，因此编译要加-pthread，但是使用这种方式使用起来很繁琐，并且效率很低。
            * 创建一个键（key），，用以将不同的线程特有数据区分开来。调用函数pthread_key_create()可创建一个key，且只需要在首个调用该函数的线程中创建一次
            * 在不同线程中，使用pthread_setspecific()函数将这个key和本线程（调用者线程）中的某个变量的值关联起来，这样就可以做到不同线程使用相同的key保存不同的value。
            * 在各线程可通过pthread_getspecific()函数来取得本线程中key对应的值

* 加锁和解锁为什么会消耗系统资源?
  * 加解锁和线程切换 都要系统开销的,让出cpu的线程需要保存自己的上下文，而等待线程则是阻塞等待A线程让出CPU

* 乐观锁和悲观锁
  * 悲观锁是基于一种悲观的态度类来防止一切数据冲突，它是以一种预防的姿态在修改数据之前把数据锁住，然后再对数据进行读写，在它释放锁之前任何人都不能对其数据进行操作，直到前面一个人把锁释放后下一个人数据加锁才可对数据进行加锁，然后才可以对数据进行操作，一般数据库本身锁的机制都是基于悲观锁的机制实现的;
  * 乐观锁是对于数据冲突保持一种乐观态度，操作数据时不会对操作的数据进行加锁（这使得多个任务可以并行的对数据进行操作），只有到数据提交的时候才通过一种机制来验证数据是否存在冲突(一般实现方式是通过加版本号然后进行版本号的对比方式实现);

* 进程间的通信方式有哪些，线程间的通信方式有哪些，它们之间有哪些区别
  * 进程间的通信方式一般有七种
    * 1 管道/匿名管道（pipe)
    * 2 有名管道（namepipe)
    * 3 信号（Signal)
    * 4 信号量（semophore）
    * 5 消息队列
    * 6 共享内存
    * 7 套接字
  * 区别：
    * 匿名管道只存在于内存中，由于没有名字，只能用于亲缘关系的进程间通信（父子进程或兄弟进程之间），有名管道，关联了一个路径名，访问路径名就可以通过有名管道通信，允许无亲缘关系进程间的通信
      * 管道有很多致命的缺点
        * 只能单向传输数据，另外管道的缓冲区是有限的（管道制存在于内存中，在管道创建时，为缓冲区分配一个、·页面大小，管道所传送的是无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式，最后就是管道操作不当很容易阻塞。
    * 信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号被某个进程产生，传递给操作系统，当接收进程不阻塞时传递给接收进程，接收进程接收到信号，暂时终止当前代码执行，执行中断处理程序，然后再回到中断位置继续执行原来的代码。
    * 信号量是一个计数器，用于多进程对共享数资源的访问，它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。信号量大于0时说明该共享资源可用量大于0，有进程申请则进行p操作分配资源，将资源量-1，释放资源时进程执行v操作，将资源量+1，可以容许多个进程共享多个同类型的资源。
    * 共享内存是一块能被其他进程访问到的内存，这段共享内存由一个进程创建，但可以多个进程访问，通信速度最快。在 Linux 系统中，每个进程的虚拟内存是将需要将共享内存映射到自己的私有地址空间，当完成通信之后，所有进程都将脱离共享内存，并且由创建的进程释放该共享内存块。
      * 优点：共享内存的优点是速度快，要访问共享内存，不需要进行拷贝，只需要将共享内存映射到自己的地址空间，访问共享内存像自己的地址空间一样。
      * 缺点：
        * 共享内存没有提供同步的机制，这使得我们在使用共享内存进行进程间通信时，往往要借助其他的手段来进行进程间的同步工作，否则容易造成数据的混乱。
    * 消息队列是存放在内核的链表，我们可以在两个进程之间通过消息队列来实现进程间通信，克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点
    * 套接字，套接字是一种通信机制，进行同一个主机上不同进程或者不同主机的不同进程之间进行双向通信
  * 线程之间的通信方式一般有4钟
    * 1 全局变量，通过对变量加关键字volatile修饰
    * 2 临界区，在任意时刻只允许一个线程对临界区中共享资源进行访问，用于同一进程的不同线程之间通信
    * 3 互斥量 ：它与临界区类似，只有拥有互斥对象的线程才具有访问资源的权限，不仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享，锁定的互斥量可以设置时间，不会像临界区那样子死等。
    * 4 信号量（Semaphores）:信号量是最具历史的同步机制。信号量对象对线程的同步方式与前面几种方法不同，信号允许多个线程同时使用共享资源 ，这与操作系统中的PV操作相同。它指出了同时访问共享 资源的线程 最大数目。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。
    * 事件（信号）：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。比如在某些网络应用程序中，一个线程如A负责侦听通信端口，另外一个线程B负责更新用户数据，利用事件机制，则线程A可以通知线程B何时更新用户数据。
  
  * 请你说一下协程?
    * 概念：协程，又叫微线程，是一个无优先级的子程序调度组件，允许子程序在特定的地方挂起恢复，看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行原来的子程序。有点像linux系统进程接收到信号时，执行中断处理程序，再回到原来的程序中继续执行。
    * 协程与线程的区别 （优势）：
      * 第一个优势，与多线程相比，协程最大的优势就是协程的执行效率高，因为协程切换不是线程切换，是由程序自身控制的，而线程切换是由操作系统切换的，因此，协程的开销小于线程切换，和多线程先比，线程数量越多，协程的优势越大。
      * 第二个优势就是不需要多线程的锁机制，因为只有一个线程，不存在同时写变量的冲突，在协程中控制共享资源不加锁，只需要判断状态就好，所以执行效率比多线程高得多。
    * 其他
      * 进程和线程的任务调度是由内核控制的，是抢占式的； 协程的任务调度是在用户态完成,需要代码里显式地将CPU交给其他协程,是协作式的，采用主动让出（yield）和恢复（resume）机制。在协程上利用多核CPU呢——多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能,目前协程主要用于高性能服务器端处理高并发的情景，微信后台的基础库libco就是一个开源的c++协程库。

* 内存池、进程池、线程池：
  * 自定义内存池的思想通过这个"池"字表露无疑，应用程序可以通过系统的内存分配调用预先一次性申请适当大小的内存作为一个内存池，之后应用程序自己对内存的分配和释放则可以通过这个内存池来完成。只有当内存池大小需要动态扩展时，才需要再调用系统的内存分配函数，其他时间对内存的一切操作都在应用程序的掌控之中。 应用程序自定义的内存池根据不同的适用场景又有不同的类型。 从线程安全的角度来分，内存池可以分为单线程内存池和多线程内存池。单线程内存池整个生命周期只被一个线程使用，因而不需要考虑互斥访问的问题；多线程内存池有可能被多个线程共享，因此则需要在每次分配和释放内存时加锁。相对而言，单线程内存池性能更高，而多线程内存池适用范围更广。
  * 从内存池可分配内存单元大小来分，可以分为固定内存池和可变内存池。所谓固定内存池是指应用程序每次从内存池中分配出来的内存单元大小事先已经确定，是固定不变的；而可变内存池则每次分配的内存单元大小可以按需变化，应用范围更广，而性能比固定内存池要低。

### go协程了解

* 进程 线程 和 协程 之间概念的区别

  * 对于 进程、线程，都是有内核进行调度，有 CPU 时间片的概念，进行 抢占式调度（有多种调度算法）

  * 对于 协程(用户级线程)，这是对内核透明的，也就是系统并不知道有协程的存在，是完全由用户自己的程序进行调度的，因为是由用户程序自己控制，那么就很难像抢占式调度那样做到强制的 CPU 控制权切换到其他进程/线程，通常只能进行 协作式调度，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到
  * 内存消耗方面
    * 协程占用内存更少
  * 切换 调度开销方面
    * 协程不用抢占内核，只有3个寄存器修改 pc/sp/dx

* go routine 和协程区别
  * go routine 就是协程
  * Golang 在 runtime、系统调用等多方面对 go routine 调度进行了封装和处理，当遇到长时间执行或者进行系统调用时，会主动把当前 go routine 的CPU (P) 转让出去，让其他 go routine 能被调度并执行，也就是 Golang 从语言层面支持了协程。Golang 的一大特色就是从语言层面原生支持协程，在函数或者方法前面加 go关键字就可创建一个协程。

### 协程底层实现原理

* 他和线程的原理是一样的，当 a线程 切换到 b线程 的时候，需要将 a线程 的相关执行进度压入栈，然后将 b线程 的执行进度出栈，进入 b线程 的执行序列。协程只不过是在 应用层 实现这一点。但是，协程并不是由操作系统调度的，而且应用程序也没有能力和权限执行 cpu 调度

* 怎么解决这个问题？
  * 协程是基于线程的。内部实现上，维护了一组数据结构和 n 个线程，真正的执行还是线程，协程执行的代码被扔进一个待执行队列中，由这 n 个线程从队列中拉出来执行。这就解决了协程的执行问题。

* 那么协程是怎么切换的呢？
  * golang 对各种 io函数 进行了封装，这些封装的函数提供给应用程序使用，而其内部调用了操作系统的异步 io函数，当这些异步函数返回 busy 或 bloking 时，golang 利用这个时机将现有的执行序列压栈，让线程去拉另外一个协程的代码来执行，基本原理就是这样，利用并封装了操作系统的异步函数。包括 linux 的 epoll、select 和 windows 的 iocp、event 等。

* golang是从编译器和语言基础库多个层面对协程做了实现，所以，golang的协程是目前各类有协程概念的语言中实现的最完整和成熟的。十万个协程同时运行也毫无压力。关键我们不会这么写代码。但是总体而言，程序员可以在编写 golang 代码的时候，可以更多的关注业务逻辑的实现，更少的在这些关键的基础构件上耗费太多精力

### 协程的历史和特点

* 协程（Coroutine）是在1963年由Melvin E. Conway USAF, Bedford, MA等人提出的一个概念。而且协程的概念是早于线程（Thread）提出的。但是由于协程是非抢占式的调度，无法实现公平的任务调用。也无法直接利用多核优势。因此，我们不能武断地说协程是比线程更高级的技术。
  * 尽管，在任务调度上，协程是弱于线程的。但是在资源消耗上，协程则是极低的。一个线程的内存在 MB 级别，而协程只需要 KB 级别。而且线程的调度需要内核态与用户的频繁切入切出，资源消耗也不小。

* 特点
  * 协程调度机制无法实现公平调度
  * 协程的资源开销是非常低的，一台普通的服务器就可以支持百万协程。

### golang协程的应用

* ，协程（coroutine）是Go语言中的轻量级线程实现，由Go运行时（runtime）管理。

* 在一个函数调用前加上go关键字，这次调用就会在一个新的goroutine中并发执行。当被调用的函数返回时，这个goroutine也自动结束。需要注意的是，如果这个函数有返回值，那么这个返回值会被丢弃。

```
func Add(x, y int) {
    z := x + y
    fmt.Println(z)
}
 
func main() {
    for i:=0; i<10; i++ {
        go Add(i, i)
    }
}
```

* 在工程上，有两种最常见的并发通信模型：共享内存 和 消息
  * 事实上 Go 语言主要使用消息机制（channel）来作为通信模型

```
package main
 
import (
    "fmt"
    "sync"
    "runtime"
)
 
var counter int = 0
 
func Count(lock *sync.Mutex) {
    lock.Lock() // 上锁
    counter++
    fmt.Println("counter =", counter)
    lock.Unlock()   // 解锁
}
 
func main() {
    lock := &sync.Mutex{}
 
    for i:=0; i<10; i++ {
        go Count(lock)
    }
    for {
        lock.Lock() // 上锁
        c := counter
        lock.Unlock()   // 解锁
 
        runtime.Gosched() // 出让时间片
 
        if c >= 10 {
            break
        }
    }
}
```

* channel
  * 消息机制认为每个并发单元是自包含的、独立的个体，并且都有自己的变量，但在不同并发单元间这些变量不共享。每个发单元的并输入和输出只有一种，那就是消息。
  * channel 是 Go 语言在语言级别提供的 goroutine 间的通信方式，我们可以使用 channel 在多个 goroutine 之间传递消息。channel是进程内的通信方式，因此通过 channel 传递对象的过程和调用函数时的参数传递行为比较一致，比如也可以传递指针等。channel 是类型相关的，一个 channel 只能传递一种类型的值，这个类型需要在声明 channel 时指定。

## 中断

* 中断
  * 中断是指处理器对系统中或系统外发生的某事件的响应。当事件发生后,操作系统保留当前进程的现场后自动地转去执行该事件的中断处理程序；执行完后，再返回到原进程的断点处继续执行。
  * 例子：就好像你正在看书,此时电话响了(异步事件),于是用书签记住正在看的那一页(中断点),再去接电话(响应异步事件并进行处理),接完电话后再从被打断那页继续向下看(返回原程序的中断点执行)。
  * 中断可以分为两种
    * 外中断:异步中断是指由其他硬件设备依照 CPU 时钟信号随机产生，即意味着中断能够在指令之间发生，例如键盘中断,磁盘中断、打印机中断等
      * 比如这个键盘键入数据完毕等
    * 内中断(同步中断),也就是异常：是指由于 CPU 内部事件所引起的中断，如程序出错(非法指令、地址越界)。内中断(trap)也被译为“捕获”或“陷入”。

    * 内中断成为同步中断的原因：同步中断是当指令执行时由 CPU 控制单元产生，之所以称为同步，是因为只有在一条指令执行完毕后 CPU 才会发出中断，而不是发生在代码指令执行期间，比如系统调用。

    * 相同点：都是CPU对系统发生的某个事情做出的一种反应
    * 区别：中断由外因引起，异常由CPU本身原因引起。

  * 引入中断的原因
    * 外中断的引入
      * 操作系统需要对连接到计算机上的所有硬件设备进行管理，要管理这些设备，首先得和它们互相通信，就是通过中断进行通信，为了支持CPU与设备之间的并行操作
        * 当CPU启动设备进行输入/输出后，设备就可以独立工作，CPU去执行其他事情，当设备完成工作后，通过触发中断信号报告 CPU此次输入/输出的结构，让CPU去处理结果
    * 内中断（异常）的引入
      * CPU执行指令时本身出现的问题
      * 如算术溢出，除0，越界访问等，此时硬件改变了CPU当前的执行流程，转到相应的错误处理程序或者异常处理程序或者执行系统调用。

  * 引起中断的事件称为中断事件或中断源;
  * 中断源向处理器发出的请求信号称为中断请求
  * 把处理中断事件的程序称为中断处理程序;
  * 发生中断时正在执行的程序的暂停点叫作中断断点;
  * 处理器暂停当前程序转而处理中断的过程称为中断响应。
  * 中断处理结束之后恢复原来程序的执行被称为中断返回。

  * 物理层面的中断其实是一种电信号，由硬件设备产生，直接送到中断控制器中，再传递给中央处理器，cpu一经检测到该信号，就会停止当前的工作，去处理中断，cpu会告诉操作系统，由操作系统进行处理。

  * 操作系统层的中断是这样的
    * 操作系统会维护中断源的有序集合，称为中断字，x86系统一般可以256中中断。
    * 为了使得中断装置可以找到恰当的中断处理程序,专门设计了中断处理程序入口地址映射表，即是中断描述表IDT,表中的每一项称为一个中断向量,记录中每一个中断与其相应的中断处理函数的入口地址，一般在系统初始化前，将IDT表的地址放到idtr寄存器，然后初始化每一项，每个能够产生中断的设备或者模块都会在内核中注册一个中断处理程序到IDT表。

  * 系统的中断的触发一般分几种情况
    * 外部设备主动发起的中断信号，用于向操作系统通知某个时间到达
    * 进程同步使用硬件资源（网卡，声卡），由于需要阻塞等待资源或者响应耗时，为了cpu更高效地被使用，也会触发中断机制，切换当前执行的进程。
    * 操作系统做进程调度时，进程要按照优先级轮流使用CPU时间片，切换进程时会触发软中断机制。

  * 中断处理流程：
    * 当物理层的中断信号或者软中断信号CPU的时候，CPU会挂起当前进程，然后保存现场，将进程的上下文到自己的地址空间（程序状态字，程序计数器等存入系统堆栈），
    * 根据中断信号，到IDT表中查找相应的中断处理程序的入口地址
    * 将处理器的pc值置为中断处理程序的入口地址，调用中断处理程序进行处理
    * 处理完后，再恢复当前进程的执行。

  * 操作系统的中断号在哪？
    * 中断号是操作系统分配给每个中断源的代号，以便识别和处理，CPU通过中断号到中断描述表IDT中找中断处理程序的入口地址
  * 中断号一般在程序代码中，通过终端号可以换算为一个指针（n)*4，指针指向IDT表的中断向量，取出中断处理程序的入口地址，转而执行中断处理程序

## 内存管理

* 内存泄漏是什么？
  * 动态分配的堆内存忘记了释放，导致内存无法回收
* 内存模型有哪几种？
  * 栈空间：主要存储局部的非静态变量，
  * 静态内存：存储局部的静态变量，类的静态成员，以及函数外的静态变量
  * 堆是动态存储区，主要存放程序运行时创建的动态内存对象，用new创建
  * 其中栈和静态内存的对象都是由编译器分配和销毁，栈中的局部变量程序运行时才存在，而静态变量从定义开始到程序结束。堆的动态对象由程序分配，生存周期由程序决定，需要显式销毁。
* 什么是内存对齐？：
  * 计算机内存空间是按照byte字节划分的，任何类型变量的访问可以从任何地址开始，但是实际的操作系统对基本数据类型在内存的位置有限制，要求它们的首地址的值是某个数k的倍数（k为4或者8byte)，这就是内存对齐
    * 如理论上，32位系统下，int占4byte，char占一个byte，那么将它们放到一个结构体中应该占4+1=5byte；但是实际上，通过运行程序得到的结果是8 byte，这就是内存对齐所导致的
    * 为什么要进行内存对齐？
      * 内存是以字节为单位，但是大部分cpu都是按照双字节的倍数来存取内存（内存存取粒度），如果没有内存对齐，数据任意放，则会造成寻址时间的浪费（比如一个int从1开始存储到5，需要获取0到8字节然后剔除不需要的字节再合并到寄存器，浪费了cpu时间，是以空间换时间
    * 结构体/类内存对齐有两个规则
      * 一是当前变量的存储地址距离0地址的距离是变量大小的整数倍
      * 二是，结构体的总的大小必须是它的变量中占用最大存储空间的整数倍。

### 虚拟内存

* 操作系统的虚拟内存是什么？

  * 虚拟内存的思想
    * 在计算机中运行的程序，其代码、数据和堆栈的总量可以超过实际内存的大小，操作系统只将当前使用的程序块保留在内存中，其余的程序块则保留在磁盘上。必要时，操作系统负责在磁盘和内存之间交换程序块。

  * 虚拟内存是计算机系统内存管理的一种技术，每个进程创建加载的时候，会被分配一个大小为4G的连续的虚拟地址空间，虚拟的意思就是，其实这个地址空间时不存在的，仅仅是每个进程“认为”自己拥有4G的内存，而实际上，进程所看到的是虚拟页表所表示的虚拟地址空间，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。它用了多少空间，操作系统就在磁盘上划出多少空间给它，等到进程真正运行的时候，需要某些数据并且数据不在物理内存中，才会触发缺页异常，进行数据拷贝

* 为什么要使用虚拟内存呢，因为多个进程直接共用同一个物理内存会出现很多问题
  * 可用性
    * 当系统执行一个程序或者说开启一个进程并执行它的时候，一般都需要将进程的所有信息都加载到内存中，然后才能让CPU执行，因为内存是直接与CPU交互的,作业很大时，不能全部装入内存，导致大作业无法运行：(比如大型的游戏)
  * 并发度
    * 当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降。
  * 驻留性
    * 一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源。
  * 使用效率
    * 当多个进程同时运行，需要分配给进程的内存总和大于实际可用的物理内存时，需要将其他程序暂时拷贝到硬盘当中，然后将新的程序装入内存运行。由于大量的数据频繁装入装出，内存的使用效率会非常低

  * 外部碎片
    * 多个进程频繁地切分物理内存，各个进程对内存的使用会导致内存碎片化，当要用malloc分配一块很大的内存空间时，可能会出现虽然有足够多的空闲物理内存，却没有足够大的连续空闲内存这种情况，东一块西一块的内存碎片就被浪费掉了

  * 安全性
    * 用户进程可以直接访问到内核的物理内存，存在危险，容易造成系统崩溃
    * 由于多程序运行在物理内存上，程序之间没有什么安全保护措施，我们访问 A 程序的数据地址时，可能由于我们的疏忽，错访问成了 B 程序的数据地址，这样就可能导致 B 程序出现莫名其妙的问题或者直接崩溃。

  * 为了解决这些问题就提出了虚拟内存

* 局部性原理：
  * 虚拟存储技术是基于局部性原理提出来的
  * 分类
    * 时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次被执行；如果某个数据被访问过，不就之后该数据很有可能再次被访问。（因为程序中存在大量的循环）
    * 空间局部性：一旦程序访问了某个存户单元，在不久之后，其附近的存储单元也很有可能被访问。（因为很多数据在内存中都是连续存放的）。
  * 时间局部性和空间局部性统称为局部性原理。

* 分段：分段提供了隔绝各个代码、数据和堆栈区域的机制，它把处理器可寻址的线性地址空间划分成一些较小的称为段的受保护地址空间区域，逻辑地址变线性地址

* 虚拟内存整体流程分为4步
  * １．CPU 产生一个虚拟地址
  * ２．获取相应的物理地址
    * MMU 从 TLB 中获取页表，翻译成物理地址，TLB没有则进行翻译
  * ３．MMU 把物理地址发送给主存
  * ４．主存将地址对应的数据返回给 CPU

* 为什么要使用快表TLB
  * CPU 通过生成一个虚拟地址来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址。将虚拟地址转换成物理地址需要内存管理单元（MMU,Memory Management Unit）进行配合，而 MMU 属于 CPU 芯片硬件的一部分
  * MMU 地址翻译过程中存在一种叫页表的数据结构，是由它来保存虚拟地址转换成物理地址的映射关系。每次 MMU 将一个虚拟地址转换为物理地址时，都会从内存中读取对应的页表。这样非常消耗时间，MMU 地址翻译效率会极大地降低。
  * 使用快表可以缓存虚拟地址到物理地址的映射关系，减少MMU进行地址翻译的次数。

* 虚拟内存转换
  * 虚拟内存是计算机的内存管理的重要组成部分，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间，32位机上是4GB,其中3-4G是内核地址空间，1-3G是用户地址空间），就是通过虚拟页表去实现，操作系统为每个进程创建一个虚拟页表，虚拟页表的每一页通过地址转换，映射到物理页表的某一页
  * 操作系统有一块物理内存，这是所有进程共用的，只有一份，也就是我们常说的内存条（32位机器下最大寻址是4G)
  * 当创建进程时，操作系统就会给它创建一个虚拟页表，它所表示的大小跟物理内存一样大，告诉进程，你能用的是一整块内存 ，但其实只是画了个大饼，并不是真的，当进程要申请内存时，系统会给进程分配的是虚拟内存地址，而操作系统背后是将虚拟内存地址转换为物理内存地址，映射到物理内存的某些页面，这些才是真正使用的物理内存，但进程并不知道这个过程，进程只需要使用虚拟内存就可以了。

  * 虚拟内存是通过页表实现的，分为虚拟页表和物理页表两种
    * 虚拟页表给给单个进程所使用，而物理内存是所有进程共有的，所以一个应用程序从编辑到被执行，需要进行映射，一次是映射 到虚拟内存，一次是映射到物理内存，映射的工作由MMU完成（存储管理单元）

  * linux将虚拟内存分为4Kb大小的存储单元，称为页，为了换入换出方便，物理内存也分为4Kb的物理块，在系统启动时，操作系统将整个物理内存以 4K 为单位，划分为各个页。之后进行内存分配时，都以页为单位

  * 虚拟内存页到物理内存页的映射就是通过页表实现，记录着虚拟地址空间和物理内存地址之间转换信息。

* 可执行程序到执行的过程，页面的访问属性是在什么时候修改的
  * shell./a.out运行可执行文件
  * 创建一个子进程，父进程的复制品
  * 调用execve系统调用启动加载器，创建子进程自己地址空间，通过将虚拟地址空间中的页映射到可执行文件的页大小组块，新的代码和数据段被初始化为可执行文件的内容
  * 最后将CUP指令寄存器设置成可执行文件入口，启动运行
  * 可执行文件的真正指令和数据都没有别装入内存中。操作系统只是通过可执行文件头部的信息建立起可执行文件和进程虚拟内存之间的映射关系而已
  * 操作系统根据虚拟地址空间与可执行文件间的映射关系找到页面在可执行文件中的偏移，然后在物理内存中分配一个物理页面，并在虚拟地址页面与物理页面间建立映射，最后把文件中页面拷贝到物理页面

* 分段：分段提供了隔绝各个代码、数据和堆栈区域的机制，它把处理器可寻址的线性地址空间划分成一些较小的称为段的受保护地址空间区域，逻辑地址变线性地址

* 分页：
  * 多级页表的原因
    * 一个程序的虚拟空间为4GB，页表以4KB为一页，那么这个程序空间就是1M页。为了存储这1M页的页指针，那么这个页表的长度就相当大了，对内存的负担也很大了。所以，最好对页表也进行分页存储，在程序运行时只把需要的页复制到内存，而暂时不需要的页就让它留在辅存中。
  * linux的虚拟内存就分为三级页表
  * 当进程访问内存时访问到的是虚拟内存，CPU会把虚拟地址传递给内存管理单元MMU，由MMU将虚拟地址转换为物理内存地址，
    * 32位地址，划分为3个部分 10 10 12,分别代表着页全局目录表pgd，页中间目录表pmd,以及页表pte

      * 第一级表称为页目录表。它被存放在1页4k页面中，具有2^10（1k）个4 字节长度的表项。这些表项指向二级表。页目录表首地址存储在寄存器中，线性地址最高10位作为索引定位到中间目录表（寄存器的页目录表基地址+页目录表偏移量 -> 得到中间目录表的基地址）
  
      * 第二级表称为中间目录，长度也是1个页面。线性地址高10位获取指向第二级页表的首地址，再加上中间10位，就可以得到一个指向页表的首地址

      * 地址的低12位就是页表的偏移量，这样就组成了一个完整的32位物理地址

  * 为了应用上的灵活，linux采用一系列宏定义掩盖平台的细节，用户可以在config配置文件中根据需求对页表进行配置，决定采用二级页表还是三级页表。

* 缺页中断
  * 进程运行时，CPU访问的是用户空间的虚地址，Linux仅把当前要使用的少量页面装入内存，需要时再通过请页机制将特定的页面调入内存

  * 页虚存面到物理页框的映射叫做页面的加载，处理器试图访问一个虚存页面时，首先到页表中去查询该页是否已映射到物理页框中，并记录在快表中。

    * 如果在，则MMU会把页码转换成页框码，并加上虚拟地址提供的页内偏移量形成物理地址后去访问物理内存

    * 当要访问的虚页不在内存时，则意味着该虚存页面还没有被载入内存，这时产生一个页故障并报告故障原因，产生一个缺页中断

    * 在中断处理程序中，系统切到内核态，启用请求分页机制
      * 程序出现错误，例如，要访问的虚地址在PAGE_OFFSET（3GB）之外，则该地址无效， Linux 将向进程发送一个信号并终止进程的运行；

    * 虚地址有效，但其所对应的页当前不在物理内存中，即缺页异常
      * 这时，如果物理内存还有空间，直接将内容载入物理内存
      * 如果没有空闲的物理内存，则作系统必须用页面置换算法从磁盘或交换文件（此页被换出）中将其装入物理内存。

    * 要访问的虚地址被写保护，即保护错误，这时，操作系统必须判断：如果是某个用户进程正在写当前进程的地址空间，则发送一个信号并终止进程的运行。但是，如果错误发生在一旧的共享页上时，则处理方法有所不同，也就是要对这一共享页进行复制，这就是曾经描述过的“写时复制”技术。

* 页面置换算法
  * 为了公平地选择要置换的页面，linux使用LRU算法，将最近未使用的页面进行置换。
  * 先进先出算法
  * 最佳置换算法（OPT）淘汰以后不会使用的页面
  * LFU（最不常用算法）要求置换具有最小计数的页面

* i++在两个线程里边分别执行100次，能得到的最大值和最小值分别是多少？

```
i++只需要执行一条指令，并不能保证多个线程i++，操作同一个i，可以得到正确的结果。因为还有寄存器的因素，多个cpu对应多个寄存器。每次要先把i从内存复制到寄存器，然后++，然后再把i复制到内存中，这需要至少3步。从这个意义上讲，说i++是原子的并不对。

多核CPU

如此，假设两个线程的执行步骤如下： 

 1. 线程A执行第一次i++，取出内存中的i，值为0，存放到寄存器后执行加1，此时CPU1的寄存器中值为1，内存中为0；

 2. 线程B执行第一次i++，取出内存中的i，值为0，存放到寄存器后执行加1，此时CPU2的寄存器中值为1，内存中为0；

 3. 线程A继续执行完成第99次i++，并把值放回内存，此时CPU1中寄存器的值为99，内存中为99；

 4. 线程B继续执行第一次i++，将其值放回内存，此时CPU2中的寄存器值为1，内存中为1；

 5. 线程A执行第100次i++，将内存中的值取回CPU1的寄存器，并执行加1，此时CPU1的寄存器中的值为2，内存中为1；

 6. 线程B执行完所有操作，并将其放回内存，此时CPU2的寄存器值为100，内存中为100；

 7. 线程A执行100次操作的最后一部分，将CPU1中的寄存器值放回内存，内存中值为2；

 8. 结束！

所以该题目便可以得出最终结果，最小值为2，最大值为200。

单核CPU

最小值100  最大值200
两个线程分别记为线程1和线程2，i++相当于取出i的值，加1，再放回去
第一种极端情况：每次线程一取出i的值后CPU时间切换到线程二，线程二也取出i的值，取到的值和线程一相等，线程二给i加一后放回去，线程一也将i加一后放回去，放回去的值也相等，相当于两个线程都执行一次i++操作，i的值只增加1，这样操作100次i的值为100
第二种极端情况：线程一和线程二间隔操作，即线程一对i++操作完成，把已经加一的数据放回去之后线程二再操作，轮流进行，最后每个线程都对i加了100次，i的值为200
```

### 文件系统

* linux硬链接和软连接的区别
  * Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。

* hard link
  * 文件A是文件B的硬链接，则A的目录项中的inode节点号与B的目录项中的inode节点号相同，即一个inode节点对应两个不同的文件名，两个文件名指向同一个文件，A和B对文件系统来说是完全平等的。如果删除了其中一个，对另外一个没有影响。每增加一个文件名，inode节点上的链接数增加一，每删除一个对应的文件名，inode节点上的链接数减一，直到为0，inode节点和对应的数据块被回收。
  * 作用
    * 硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。只删除一个连接并不影响节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。

* 软链接(soft link)：A是B的软链接（A和B都是文件名），A的目录项中的inode节点号与B的目录项中的inode节点号不相同，A和B指向的是两个不同的inode，继而指向两块不同的数据块。但是A的数据块中存放的只是B的路径名（可以根据这个找到B的目录项）。A和B之间是“主从”关系，如果B被删除了，A仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。软链接可以理解成快捷方式。它和windows下的快捷方式的作用是一样的。软链接文件只是维持了从软链接到源文件的指向关系（从jys.soft->jys可以看出），不是源文件的内容，大小不一样容易理解。
  * 软链接又称之为符号连接（Symbolic Link）。软链接文件类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息
