# 数据结构问题

## 数组与链表

* 数组和链表的区别
  * 数组是顺序存储结构，在内存中是一块连续的存储空间，在申请数组的时候就指定大小，可以实现随机查询，查询快
  * 链表是链式存储结构，在内存中是一个个结点通过指针的指向链接起来的，可以实现动态扩增，只需要在插入位置改变前后节点的指针指向即可，但是只能从表头进行顺序遍历。

## 树

### 二叉排序树（二叉搜索树）BST

* 二叉排序树（Binary Sort Tree),即二叉查找树
  * 若左子树非空，则左子树上所有结点的值均小于它的跟结点的值
  * 若它的右子树非空，则右子树所有结点的值均大于它的根节点的值
  * 左右子树都是二叉排序树
* 二叉排序树是为了提高查找和插入删除关键字的速度

#### 插入新元素

```
//结点
typedef struct BiTNode
{
  int data;
  struct BiTNode *lchild, *rchild;
} BiTNode, *BiTree;

/*
例子：查找二叉树中是否存在指定的key
指针f指向T的双亲结点，初始值为NULL
1. 若查找成功，指针p指向该数据元素结点，返回TRUE
2，否则指针p指向查找路径上访问的最后一个结点并返回False

bool SearchBST(BiTree T,int key, BiTree f, BiTree *p)
{
  if(!T)  //若当前结点为空（叶子节点），则查找不成功
  {
    *p = f;
    return false;
  }
  else if (key == T->data) //查找成功
  {
    *p = T;
    return true;
  }
  else if( Key < T->data)
    return SearchBST(T->lchild,key,T,p); //在左子树查找
  else
    return SearchBST(T->rchild,key,T,p);  //在右子树查找
}
*/
```

#### 插入

```
/*
当二叉排序树T不存在关键字等于key的数据元素时，插入key并返回
*/
bool InsertBST(BiTree *T,int key)
{
  //p保存
  BiTree p,s;
  if(!SearchBST(*T,key,NULL,&p)) //查找不成功
  {
    s = （BiTree)malloc(sizeof(BiTNode));
    s->data = key;
    s->lchild = s->rchild = NULL;
    //若二叉树为空
    if(!p)
      *T = s; //插入根节点
    else if(key < p->data)
      p->lchild = s;  //插入左孩子
    else
      p->rchild = s;  //插入右孩子
  }
  else
    return false; //已存在该关键字的结点，不再插入
}
```

#### 分析

* 以链表的方式存储结点，方便插入删除结点，只需要修改链接指针即可
* 从根路径向下查找，比较次数等于给定结点在二叉排序树的层数
  * 时间复杂度O(logn)
  * 斜二叉树是最坏结果O(n)

### 平衡二叉树 BBST

* 介绍平衡二叉树
  * 一个特殊的二叉排序树
    * 左右子树深度之差的绝对值不超过1
    * 左右子树仍然为平衡二叉树
  * 若向平衡二叉树中插入一个新结点后破坏了平衡二叉树的平衡性。首先要找出插入新结点后失去平衡的最小子树根结点的指针，调整链接关系成为新的平衡二叉树
    * LL:由于在A的左孩子B的左子树上插入结点F，使A的平衡因子由1增至2而失去平衡。故需进行一次顺时针旋转操作。即将A的左孩子B向右上旋转代替A作为根结点，A向右下旋转成为B的右子树的根结点。而原来B的右子树则变成A的左子树。
    * RR: 由于在A的右孩子C 的右子树上插入结点F，使A的平衡因子由-1减至-2而失去平衡。故需进行一次逆时针旋转操作。即将A的右孩子C向左上旋转代替A作为根结点，A向左下旋转成为C的左子树的根结点。而原来C的左子树则变成A的右子树。
    * LR型平衡旋转法:先逆时针转为LL型， 再LL型处理
      * 由于在A的左孩子B的右子数上插入结点F，使A的平衡因子由1增至2而失去平衡。故需进行两次旋转操作（先逆时针，后顺时针）。即先将A结点的左孩子B的右子树的根结点D向左上旋转提升到B结点的位置，然后再把该D结点向右上旋转提升到A结点的位置。即先使之成为LL型，再按LL型处理。
    * RL： 由于在A的右孩子C的左子树上插入结点F，使A的平衡因子由-1减至-2而失去平衡。故需进行两次旋转操作（先顺时针，后逆时针），即先将A结点的右孩子C的左子树的根结点D向右上旋转提升到C结点的位置，然后再把该D结点向左上旋转提升到A结点的位置。即先使之成为RR型，再按RR型处理。

### 红黑树

* 介绍一下红黑树
  * 红黑树是一种特殊的二叉查找树，每个节点都有存储位表示节点的颜色（红色 或者 黑色）
  * 特征：
    * 每个节点要么是红色，要么是黑色
    * 根节点是黑色
    * 每个叶子节点也是黑色(NULL)
    * 红色节点的孩子一定是 黑色的
    * 任意结点 到 叶子节点 的任意路径上 黑色节点的个数是相同的
    * 没有一条路径会比其他路径长出两倍，接近与平衡二叉树

  * 红黑树的时间复杂度 O(log N )

  * 为什么要有红黑树呢
    * 一开始：二叉查找树可能退化为斜树（链表）
    * 接着为了解决这个问题提出了AVL树
    * 但是因为平衡二叉树是严格的平衡，左右子树的高度差 <2,维护起来比较麻烦，耗费时间，所以提出了红黑树
    * 红黑树是接近于 平衡二叉树，左右子树的深度差 <=2,采用了折中的办法，解决了AVL的缺点

  * 变化规则
    * 子树根节点是 红节点
    * 父节点是 黑节点 -> 不变
    * 父节点是 红节点， uncle 是黑节点
      * 直线：顺着直线的方向旋转（ LL）
      * 三角：逆着直线的方向旋转
    * 父节点是 红节点， uncle 是红节点
      * 变色

  * 红黑树的基本操作
    * 左旋转和右旋
      * 红黑树的基本操作是添加、删除。在对红黑树进行添加或删除之后，都会用到旋转方法,让树保持红黑树的特性
      * 根节点左旋
        * 要旋转的根节点成为左子树
        * 原本的右子树成为根节点
        * 原来右子树的左节点成为被旋转的根节点的右子树
      * 根节点右旋
        * 要旋转的根节点成为右子树
        * 原本左子树成为 根节点
        * 原本左子树的右子树成为被旋转节点的左子树

* 红黑树与哈希表的优劣
  * 权衡红黑树的三个因素
    * 查找速度
    * 数据量
    * 内存使用
    * 是否有序
    * 可扩展性
  * 红黑树是一个特殊的二叉排序树，有序的，占用的内存更少，红黑树的查找和插入删除的时间复杂度都是O(logN)，可以实现动态扩展，但是数据量大的时候维持红黑树的时间成本会变大
  * 而哈希表无序，只关注元素是否存在哈希表中，查找和增删的时间复杂度都是O(1),但是的大小需要再定义哈希表的时候确定，而且存储哈希表耗费的内存较大

* 哈希表和红黑树的使用场景
  * 如果要求元素有序，内存占用小，可扩展性强而数据量较少则使用红黑树
  * 如果内存容量大，更关注于元素是否存在而不是有序，数据量比较大则使用哈希表

* 解决哈希冲突的方法
  * 由于元素经过哈希函数计算后的值相同而产生了哈希冲突，解决的办法有
    * 开放地址法：从发生冲突单位按照一定的次序向前或者向后探测一个空闲单元存储，查询的时候也是照样子查询
    * 链地址法（拉链法）：将哈希值相同的元素构成一个单链表，用一个哈希表去管理单链表的表头
    * 再次哈希法：哈希冲突时采用备用的哈希算法继续算哈希值
    * 建立公共溢出区

### B树（平衡的多路查找树）

* 原因
  * 因为我们要考虑磁盘IO的影响，它相对于内存来说是很慢的。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。所以我们要减少IO次数，对于树来说，IO次数就是树的高度，而“矮胖”就是b树的特征之一，它的每个节点最多包含m个孩子，m称为b树的阶，m的大小取决于磁盘页的大小。

* 多路查找树：每一个结点的孩子数可以多于两个，且每一个结点处可以存储多个元素

* 2-3/2-3-4树都是B树的特例，节点最大的孩子数目是B树的阶

* 一棵m阶B树(balanced tree of order m)是一棵平衡的m路搜索树。它的特性
  * 根节点至少有两棵子树
  * 根结点的儿子数为[2, M]；
  * 除根结点以外的非叶子结点的儿子数为[M/2, M]；
  * 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字）
  * 所有叶子节点都在同一层

* B树的查找
  * 根结点开始，对结点内的关键字（有序）序列进行二分查找，如果命中则结束，否则进入查询关键字所属范围的儿子结点；重复，直到所对应的儿子指针为空，或已经是叶子结点
  * 过程是个顺指针查找结点和在结点种查找关键字的交叉过程，瓶颈是经常在内存与外存之间交换数据。
  * 先将结点加入内存，再找关键字

### B+树

* B+树的定义
  * 是应文件系统所需而出的一种B-树的变型树
  * 有n棵子树的结点中含有n个关键字，每个关键字不保存数据，只用来索引，所有数据都保存在叶子节点。
  * 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接
  * 所有的非终端结点可以看成是索引部分，结点中仅含其子树（根结点）中的最大（或最小）关键字。
  * 通常在B+树上有两个头指针，一个指向根结点，一个指向关键字最小的叶子结点

* 特点：
  * 非叶子节点的子树指针与关键字个数是相同的
  * 叶子结点增加了一个链指针
  * 所有关键字都在叶子结点出现，链表的关键字是有序的
  * 非叶子结点相当于叶子节点的索引，叶子结点才是存储关键字的数据层

* B+树相对于b树的查询优势
  * b+树的结点不保存数据，所以磁盘可以容纳更多节点元素，更加矮胖,可以更加提高查询效率
  * b+树查询必须找到叶子节点，b树只要匹配到即可不用管元素位置，因此b+树查找更稳定（并不慢）
  * 对于范围查找来说，b+树只需遍历叶子节点链表即可，b树却需要重复地中序遍历

* 用途
  * B+树通常用于数据库和操作系统的文件系统中作为元数据的索引，它可以以保证数据稳定有序，插入和删除都是稳定的对数时间复杂度，元素自底而上插入

### B* 树

* B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针；

* B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分
数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字
因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之
间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针；
所以，B*树分配新结点的概率比B+树要低，空间使用率更高；

### 三种B型树的分析

* B树：
  * 多路搜索树，每个结点存储M/2到M个关键字，非叶子结点存储指向关键字范围的子结点；
  * 所有关键字在整颗树中出现，且只出现一次，非叶子结点可以命中；

* B+树：
  * 在B-树基础上，为叶子结点增加链表指针，所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中

* B*树：
  * 在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3；

* 对比
  * B-树是一种平衡的多路查找(又称排序)树，在文件系统中有所应用。主要用作文件的索引
  * B+树有一个最大的好处，方便扫库，B树必须用中序遍历的方法按序扫库，而B+树直接从叶子结点挨个扫一遍就完了。
  * B+树支持range-query(区间查询)非常方便，而B树不支持。这是数据库选用B+树的最主要原因。

* 有很多基于频率的搜索是选用B树，越频繁query的结点越往根上走，前提是需要对query做统计，而且要对key做一些变化。
另外B树也好B+树也好，根或者上面几层因为被反复query，所以这几块基本都在内存中，不会出现读磁盘IO，一般已启动的时候，就会主动换入内存。 mysql底层存储是用B+树实现的，因为内存中B+树是没有优势的，但是一到磁盘，B+树的威力就出来了。

## 排序算法

* 手写快排

```
//切分排序
int split(int a[], int low, int high)
{
    int temp = a[low];

    while(low < high)
    {
        //从右边找第一个小于基数的数
        while(low < high && temp <= a[high])
            high--;
        if(low >= high)
            break;
        a[low++] = a[high];
        //从左边找第一个大于基数的数
        while(low < high && a[low] <= temp)
            low++;
        if(low >= high)
            break;
        a[high--] = a[low];
    }
    a[high] = temp;
    return high;
}
void quick_sort(int a[], int low, int high)
{
    int middle;

    if(low > high)
        return;
    middle = split(a,low,high);
    quick_sort(a,low,middle-1);
    quick_sort(a,middle+1,high);
}
```

* 归并排序与快速排序的比较
  * 相同点：
    * 两种算法都采用了分治和递归的思想
  * 时间复杂度，
    * 归并排序，时间复杂度是O(nlogn)
      * 一次合并的时间是，最好的情况已经排序好了，但是还是要n/2次，比较操作，还有n次赋值操作。一次递归是O(n)
      * 然后整个归并的是一颗二叉树，树深度是log2n
      * 所以总的时间复杂度是O(nlogn).

    * 快速排序,时间复杂度比较复杂，因为这个和他的基准数选取有关，假如说基准数刚好是中间值，对半分的话，就是O(nlogn).假如基准数是最小的或者最大的， 那就变成O(n^2)
      * 最好情况
        * 在最好的情况下，每次我们进行一次分区，我们会把一个序列刚好分为几近相等的两个子序列
      * 最坏情况
        * 假设每次分区后都出现子序列的长度一个为0和 1 一个为 n-1，那真是糟糕透顶
        * 所以我们的最坏情况是 O(n²)。
      * 枢纽值选取
        * 1 固定基准数（前后）
        * 2 随机基准数
        * 3 三数取中
    * 空间复杂度。
      * 归并排序的是O(n),递归每次都要用临时数组，同一层的递归，加起来的临时数组长度和原数组长度相同。
      * 快速排序是原地排序，是O(1)。
    * 稳定性
      * 归并排序可以是稳定排序，也可以是不稳定排序 
      * 快速排序，由于来回交换数据，假如原先相等的两个数，分别在划分的两个自区间中。那么调换之后，就不会保持原来的顺序，所以是不稳定的排序。
  * 当数据量
    * 当N很小时，快速排序慢，归并排序快
    * 当N很大时，并且有序程度高时，快速排序最快
    * 当N很大时，并且有序程序低时，堆排序最快
  * 数据级别是100万以上，采用堆排序和快排较快

## 聚类算法

* 聚类(Clustering)是按照某个特定标准(如距离)把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。也即聚类后同一类的数据尽可能聚集到一起，不同类数据尽量分离。

* 聚类和分类的区别
  * 聚类(Clustering)：是指把相似的数据划分到一起，具体划分的时候并不关心这一类的标签，目标就是把相似的数据聚合到一起，聚类是一种无监督学习(Unsupervised Learning)方法。
  * 分类(Classification)：是把不同的数据划分开，其过程是通过训练数据集获得一个分类器，再通过分类器去预测未知数据，分类是一种监督学习(Supervised Learning)方法。

* 聚类的一般过程
  * 数据准备：特征标准化和降维
  * 特征选择：从最初的特征中选择最有效的特征，并将其存储在向量中
  * 特征提取：通过对选择的特征进行转换形成新的突出特征
  * 聚类：基于某种距离函数进行相似度度量，获取簇
  * 聚类结果评估：分析聚类结果，如距离误差和(SSE)等

* 硬聚类
  * 一个样本只能属于一个类。
* 软聚类
  * 一个样本可以以概率属于多个类

* 数据聚类方法
  * 划分聚类
    * 如K-means算法
      * 准备好需要的聚类的数据，然后确定簇的数量
      * 随机选择簇的数据中心
      * 计算各个数据分别跟3个中心点的哪一个点最近，将数据分到该簇中，完成一次聚类划分
      * 循环计算各个簇的重心，将簇中心移动到这个位置
      * 从新计算各个数据最近的数据中心，并将数据分到相应的簇中
      * 重复执行4，5步骤，直到簇中心点不再改变为止
    * k-means算法对于凸性数据具有良好的效果，能够根据距离来讲数据分为球状类的簇，但对于非凸形状的数据点，就无能为力了

  * 密度聚类
    * 密度的邻域半径和邻域密度阈

  * 层次聚类等
    * 前面介绍的几种算法确实可以在较小的复杂度内获取较好的结果，但是这几种算法却存在一个链式效应的现象，比如：A与B相似，B与C相似，那么在聚类的时候便会将A、B、C聚合到一起，但是如果A与C不相似，就会造成聚类误差，严重的时候这个误差可以一直传递下去。为了降低链式效应，这时候层次聚类就该发挥作用了
    * 将数据集划分为一层一层的 clusters，后面一层生成的 clusters 基于前面一层的结果。层次聚类算法一般分为两类：
      * Agglomerative 层次聚类：又称自底向上（bottom-up）的层次聚类，每一个对象最开始都是一个 cluster，每次按一定的准则将最相近的两个 cluster 合并生成一个新的 cluster，如此往复，直至最终所有的对象都属于一个 cluster。这里主要关注此类算法。
      * Divisive 层次聚类： 又称自顶向下（top-down）的层次聚类，最开始所有的对象均属于一个 cluster，每次按一定的准则将某个 cluster 划分为多个 cluster，如此往复，直至每个对象均是一个 cluster。

* 应用场景
  * 基于用户位置信息的商业选址
    * 通过大量移动设备用户的位置信息，为某连锁餐饮机构提供新店选址

  * 求职信息完善
    * 有大约10万分优质简历，其中部分简历包含完整的字段，部分简历在学历、公司规模、薪水、职位名称等字段有些置空项。希望对数据进行学习、编码与测试，挖掘出职位路径的走向与规律，形成算法模型，再对数据中置空的信息进行预测

  * 搜索引擎查询聚类以进行流量推荐
    * 在搜索引擎中， 很多网民的查询意图的比较类似的，对这些查询进行聚类，一方面可以使用类内部的词进行关键词推荐；另一方面， 如果聚类过程实现自动化，则也有助于新话题的发现；同时还有助于减少存储空间等。

  * 生物种群固有结构认知
    * 对动植物分类和对基因进行分类，获取对种群固有结构的认识。

  * 保险投保者分组
    * 通过一个高的平均消费来鉴定汽车保险单持有者的分组，同时根据住宅类型，价值，地理位置来鉴定一个城市的房产分组

## 其他

* 坐标系有一长方形，一只三个顶点坐标，求第四个顶点坐标（深信服）

```
typedef struct edge {
    int x, y;
}coor;
//对角线上的点横坐标之和等于中点横坐标的二倍这个方法求出
coor coordinate(coor a, coor b, coor c)//a点为直角点，求第4个点的坐标.
{
    coor p;
    p.x = b.x + c.x - a.x;
    p.y = b.y + c.y - a.y;
    return p;
}
//(x2-x1)*(x3-x1)+(y2-y1)*(y3-y1) == 0 则为直角
bool Judge(coor a, coor b, coor c)//判断向量数量积是否为0.
{
    if (!((b.x - a.x) * (c.x - a.x) + (b.y - a.y) * (c.y - a.y)))
        return true;
    return false;
}
void Seeking(coor a[])
{
    if (Judge(a[0], a[1], a[2]))//判断直角点.
        a[3] = coordinate(a[0], a[1], a[2]);
    else if(Judge(a[1], a[0], a[2]))
        a[3] = coordinate(a[1], a[0], a[2]);
    else a[3] = coordinate(a[2], a[0], a[1]);
    //a[3]即为第4个点.
}
```

* 解决如何衡量在不同时空共享单车资源的需求量；如何分配不同地区共享单车，使共享单车数量趋于合理；设计优化资源配置的调度方案（深信服）
  * 建立合理指标分析不同时空共享单车资源的需求量。收集相关数据并分析，以10个区域为例，分别选取不同区域总需求量、不同时间段各区域实际骑行数量、不同区域不同时间段实际骑行数量等合理指标，分析不同时间和空间上共享单车资源的需求量。结果为短距离骑行人数较多，需求更大；区域6和区域8需要骑行的总人数较多；所有区域7:30-8:00、9:00-9:30、12:00-12:30为骑行高峰期，需求量更大。
  * 结合不同区域的共享单车需求量和不同时间段不同区域共享单车的需求量以及不同区域共享的那车归还率，采取就近原则在三个高峰期分别从区域1向区域2调动20辆，区域7向区域5调度10辆，区域9向区域8调动10辆，区域10向区域8调动15辆的调度方案，从而解决共享单车的无车可用与车辆淤积问题。
  * 我们分析了调度的影响因素，主要分为两个：各个时间段各个区域共享单车的需求系数和共享单车的使用周转率。通过以上两个指标衡量共享单车的调度方案，我们求出需求矩阵以及不同时间段的各个区域的实际骑行量以及需求量，进而分析得到高峰期单车调度方案。
  * 可夫链得到的10个区域趋于稳定的共享单车需求量

* 设计一个电梯系统（3个电梯），需要考虑哪些因素
  * 单个电梯则有两个原则
    * 顺路原则
    * 就近原则
  * 多个电梯
    * 早高峰总人数，楼层高度，运行速度 占地空间，地点
    * 平均等待时间
    * 满载直接走人
    * 闲时顺路
    * 单双楼层（高低楼层）

* 为什么谷歌，百度搜索引擎这么快
  * 倒排算法
    * 百度肯定是有爬虫，到处爬取网页，进行某种处理。然后通过你输入的关键词进行某种计算再返回给你的（爬取海量网页）
    * 当百度爬取了海量网页后，每一个网页我们称为”文档“，不可能就杂乱无章的放着，它使用了文档集合，就是类似的文档放在一个集合中（类似的文档放在一个集合）
    * 百度爬取后，将他们进行编号，然后对文档进行扫描分词，因为百度内部有词库，匹配上的词将被切分，（对文档根据关键词进行划分和编号）
    * 对切分出来的单词进行倒排处理，形成倒排列表（对单词进行倒排序）
    * 倒排列表所做的，就是保存对应单词所出现过的文档编号（根据单词可以找到文档编号）

  * 例如：当我们搜索“谷歌”的时候，他就会获得“谷歌”这一单词对应的倒排列表，知道哪些文档包含他，然后将这些文档提取出来返回给你，这就是一种单词映射文档的方法

  * 倒排列表还要保存下列信息
    * 保留的信息变成了二元组
    * 记录单词对应的文档编号，出现的次数，评分 优先将次数多的排在前面
    * 这样子，搜素引擎就可以根据你的关键词在倒排列表中找到含有这个关键词的文档集合，然后根据关键词在文档集合中各个文档出现的频率和位置综合判断返回给你排序后的文档
  
  * 倒叙表中，单词以及信息形成的二元组作为倒叙索引
    * 单词对应的二元组记录单词侧耳信息，而出现次数啊，评分，出现在哪个文档等
    * 当我们要搜索找到有“运动”的文章时，先去关键词目录找，找到在1,2,3,5,7,8这几页，然后直接把书翻到这些页就能获取到相应的内容了。

* CAS算法
  * Compare And Swap 即比较并交换
  * 函数公式：CAS(V,E,N)V：表示要更新的变量E：表示预期值N：表示新值

  * 原理
    * 如果V等于E值，则将V的值设置为N
    * 不等于则表明有其他线程做了更新，当前线程内部都不做

  * 通俗点说就是
    * CAS操作需要我们提供一个期望值，当期望值与 当前线程的变量值相同时，说明没有其他 线程修改该值，当前线程可以修改该值，如果不符合就是说明该值已经被其他线程修改了，当前线程不修改，可以选择重新读取该变量再次尝试修改，也可以直接放弃操作。
  * c++的原子性+-是使用CAS算法

* 链表后加节点（CAS实现）

```
#include <iostream>       // std::cout
#include <atomic>         // std::atomic
#include <thread>         // std::thread
#include <vector>         // std::vector

// a simple global linked list:
struct Node { int value; Node* next; };
std::atomic<Node*> list_head (nullptr);

void append (int val) {     // append an element to the list
  Node* oldHead = list_head;
  Node* newNode = new Node {val,oldHead};

  // what follows is equivalent to: list_head = newNode, but in a thread-safe way:
  while (!list_head.compare_exchange_weak(oldHead,newNode)) {
    newNode->next = oldHead;
  }
}

int main ()
{
  // spawn 10 threads to fill the linked list:
  std::vector<std::thread> threads;
  for (int i=0; i<30; ++i) threads.push_back(std::thread(append,i));
  for (auto& th : threads) th.join();

  // print contents:
  for (Node* it = list_head; it!=nullptr; it=it->next)
    std::cout << ' ' << it->value;
  std::cout << '\n';

  // cleanup:
  Node* it; while (it=list_head) {list_head=it->next; delete it;}

  return 0;
}
```

* CAS可能回导致"ABA问题"
  * CAS 算法实现一个重要前提需要取出内存中某时刻的数据，而在下时刻比较并替换，那么在这个时间差类会导致数据的变化。
  * 比如说一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操作发现内存中仍然是 A，然后 one 操作成功。尽管线程 one 的 CAS 操作成功，但是不代表这个过程就是没有问题的。
  * 部分乐观锁的实现是通过版本号(version)的方式来解决 ABA 问题，乐观锁每次在执行数据的修改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行+1 操作，否则就执行失败。因为每次操作的版本号都会随之增加，所以不会出现 ABA 问题，因为版本号只会增加不会减少

* 布隆过滤器
  * 布隆过滤器是一种比较巧妙的概率型数据结构，主要用于判断一个元素是否在一个集合中，它的特点是可以高速地插入和查询数据。
  * 传统的list,set,map,hash表，平衡二叉树等数据结构可以用于判断一个元素是否存在于一个集合中，但是如果集合中的数据量足够大，这些常规的数据结构会遇到瓶颈，如果用链表，树，map等，就会使得查询的耗时太多，如果使用哈希表，查询效率上来了，但是哈希表相应消耗的内存就会很多，很难提供这么大的内存。
  * 布隆过滤器就应运而生，相对于传统的数据结构，它更高效，占用空间更少，但是缺点就是其返回的结果是概率性的，不是确切的。

  * 布隆过滤器的实现主要是一个超大的位数组和几个哈希函数。位数组的长度是m位，哈希函数的个数是k
    * 布隆过滤器添加元素操作
      * 将要添加的元素给k个哈希函数
      * 得到对应于数组的k个位置
      * 将k个位置设为1
    * 布隆过滤器查询元素操作
      * 将要查询的元素给k个哈希函数
      * 得到对应于位数组上的k个位置
      * 如果k个位置上有一个不为0，则该元素肯定不在集合中
      * 如果k个位置全部都为1，则可能在集合中，因为如果是其他元素导致相应的位置设为1，则可能造成误判。

  * 传统的布隆过滤器不支持删除操作

  * 如何选择哈希函数个数和布隆过滤器长度
    * 过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。
    * 哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那我们的误报率会变高。

### 服务器相关

* 高可用
  * 指系统无中断地执行其功能的能力，代表系统的可用性程度。是进行系统设计时的准则之一
  * 高可用性通常通过提高系统的容错能力来实现

  * 主从方式 （非对称方式）
    * 工作原理：主机工作，备机处于监控准备状况；当主机宕机时，备机接管主机的一切工作，待主机恢复正常后，按使用者的设定以自动或手动方式将服务切换到主机上运行，数据的一致性通过共享存储系统解决。

  * 双机双工方式（互备互援）
工作原理：两台主机同时运行各自的服务工作且相互监测情况，当任一台主机宕机时，另一台主机立即接管它的一切工作，保证工作实时，应用服务系统的关键数据存放在共享存储系统中。

  * 集群工作方式（多服务器互备方式）
工作原理：多台主机一起工作，各自运行一个或几个服务，各为服务定义一个或多个备用主机，当某个主机故障时，运行在其上的服务就可以被其它主机接管。

* 一致性哈希
  * 一种特殊的哈希算法，在使用一致性哈希算法之后，哈希表槽位（大小）的改变平均只需要对K/n个关键字进行重新映射，其中K是关键字的数量，n是槽位数量，然而在传统哈希表中，添加或者删除一个槽位几乎要对所有关键字进行重新映射。
  * 一致性哈希的哈希表中的每一个value代表分布式系统中的一个节点，在系统中添加或者删除节点只需要移动K/n项，实现健壮缓存来减少大型web应用中系统部分失效带来的负面影响，还应用于分布式散列表，即关键字可以通过一个连接所有节点的覆盖网络高效定位到某个节点。
  * 需求：
    * 在使用n台缓存服务器时，一种常用的负载均衡方式是，对资源o的请求使用hash(o) = o mod n 来映射到某一台缓存服务器，当增加或者减少一台缓存服务器时这种方式可能会改变所有资源对应的hash值，也就是所有的缓存都失效了，这会使得服务器大量集中地向原始内容服务器更新缓存。因此需要一致性哈希算法来避免这样的问题，
    * 一致性哈希算法尽可能使同一个资源映射到同一台缓存服务器，当要求增加一台缓存服务器时，新的服务器尽可能分担其他所有服务器的缓存资源，；减少一台缓存服务器时，其他服务器也可以尽量分担存储他的缓存资源
    * 一致性哈希算法的主要思想是将每个缓存服务器与一个或者多个哈希域区间关联起来，其中区间边界通过计算缓存服务器对应的哈希值开决定。（定义区间的哈希函数不一定和计算缓存服务器哈希值的函数相同，但是两个函数的返回值的范围需要匹配。）如果一个缓存服务器被移除，则它所对应的区间会被并入到邻近的区间，其他的缓存服务器不需要任何改变。
  * 实现：
    * 一致哈希将每个对象映射到圆环边上的一个点，系统再将可用的节点机器映射到圆环的不同位置。查找某个对象对应的机器时，需要用一致哈希算法计算得到对象对应圆环边上位置，沿着圆环边上查找直到遇到某个节点机器，这台机器即为对象应该保存的位置。 当删除一台节点机器时，这台机器上保存的所有对象都要移动到下一台机器。添加一台机器到圆环边上某个点时，这个点的下一台机器需要将这个节点前对应的对象移动到新机器上。 更改对象在节点机器上的分布可以通过调整节点机器的位置来实现。
  * 特性：
    * 一致哈希在互联网分布式缓存中非常有用的几个特性：
      * 冗余少
      * 负载均衡
      * 过渡平滑
      * 存储均衡
      * 关键词单调
  * 在亚马逊的云存储系统Dynamo的数据划分功能模块中使用一致哈希
  * 计算一致性hash步骤
    * 首先求出memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。
    * 然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。
    * 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台memcached服务器上。
  * 添加服务器node影响的地点：逆时针方向的第一台服务器上的键会受到影响

* 一致性哈希的性质
  * 分布式系统每个节点都有可能失效，并且新的节点很可能动态的增加进来，如何保证当系统的节点数目发生变化时仍然能够对外提供良好的服务，这是值得考虑的，尤其实在设计分布式缓存系统时，如果某台服务器失效，对于整个系统来说如果不采用合适的算法来保证一致性，那么缓存于系统中的所有数据都可能会失效（即由于系统节点数目变少，客户端在请求某一对象时需要重新计算其hash值（通常与系统中的节点数目有关），由于hash值已经改变，所以很可能找不到保存该对象的服务器节点），因此一致性hash就显得至关重要，良好的分布式cahce系统中的一致性hash算法应该满足以下几个方面：
    * 平衡性(Balance)
      * 平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。
    * 单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。简单的哈希算法往往不能满足单调性的要求
    * 分散性(Spread)
      * 在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。
    * 负载(Load)
      * 负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。
    * 平滑性
      * 平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。

* 一致性哈希的原理
  * 一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形）
  * 将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置
  * 使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。
  * 一致性哈希算法的容错性和可扩展性
    * 在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。
    * 如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。
    * 一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。
    * 一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题
